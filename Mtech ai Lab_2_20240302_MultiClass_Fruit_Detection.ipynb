{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyND5YXpnIBtzKGfbTrM31B+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mborkhat/MTech-Ai-2024-CV/blob/main/Mtech%20ai%20Lab_2_20240302_MultiClass_Fruit_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD3oTS3lYy8f",
        "outputId": "03a15170-ebec-4afc-d46b-d96f198c9bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 403, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /content. Or use the environment method.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR']='/content'\n",
        "!kaggle datasets download -d mbkinaci/fruit-images-for-object-detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip *.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsTEa-szZSr4",
        "outputId": "75f0dc18-ada7-4424-8aac-57d569bdaa5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open *.zip, *.zip.zip or *.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AwPAwnpba32v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout\n",
        "from keras.models import Sequential\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(1)"
      ],
      "metadata": {
        "id": "BtrpezCXZGqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing training data\n",
        "# -> appending images in a list 'train_images'\n",
        "# -> appending labels in a list 'train_labels'\n",
        "\n",
        "train_images = []\n",
        "train_labels = []\n",
        "shape = (200,200)\n",
        "train_path = 'train_zip/train'\n",
        "\n",
        "for filename in os.listdir('train_zip/train'):\n",
        "    if filename.split('.')[1] == 'jpg':\n",
        "        img = cv2.imread(os.path.join(train_path,filename))\n",
        "\n",
        "        # Spliting file names and storing the labels for image in list\n",
        "        train_labels.append(filename.split('_')[0])\n",
        "\n",
        "        # Resize all images to a specific shape\n",
        "        img = cv2.resize(img,shape)\n",
        "\n",
        "        train_images.append(img)\n",
        "\n",
        "# Converting labels into One Hot encoded sparse matrix\n",
        "train_labels = pd.get_dummies(train_labels).values\n",
        "\n",
        "# Converting train_images to array\n",
        "train_images = np.array(train_images)\n",
        "\n",
        "# Splitting Training data into train and validation dataset\n",
        "x_train,x_val,y_train,y_val = train_test_split(train_images,train_labels,random_state=1)"
      ],
      "metadata": {
        "id": "wDQsLOqKa--n",
        "outputId": "98f9f7c7-f2c6-410c-bbdb-6f235d167e73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train_zip/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-96efa9cbd2f7>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train_zip/train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_zip/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'jpg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_zip/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing testing data\n",
        "# -> appending images in a list 'test_images'\n",
        "# -> appending labels in a list 'test_labels'\n",
        "# The test data contains labels as well also we are appending it to a list but we are'nt going to use it while training.\n",
        "\n",
        "test_images = []\n",
        "test_labels = []\n",
        "shape = (200,200)\n",
        "test_path = 'test_zip/test'\n",
        "\n",
        "for filename in os.listdir('test_zip/test'):\n",
        "    if filename.split('.')[1] == 'jpg':\n",
        "        img = cv2.imread(os.path.join(test_path,filename))\n",
        "\n",
        "        # Spliting file names and storing the labels for image in list\n",
        "        test_labels.append(filename.split('_')[0])\n",
        "\n",
        "        # Resize all images to a specific shape\n",
        "        img = cv2.resize(img,shape)\n",
        "\n",
        "        test_images.append(img)\n",
        "\n",
        "# Converting test_images to array\n",
        "test_images = np.array(test_images)"
      ],
      "metadata": {
        "id": "Cj4HlzV7bC6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing Training data\n",
        "print(train_labels[0])\n",
        "plt.imshow(train_images[0])"
      ],
      "metadata": {
        "id": "trglhYZMcIEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing Training data\n",
        "print(train_labels[4])\n",
        "plt.imshow(train_images[4])"
      ],
      "metadata": {
        "id": "xcCKCkzMcJqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Sequential model\n",
        "model= Sequential()\n",
        "model.add(Conv2D(kernel_size=(3,3), filters=32, activation='tanh', input_shape=(200,200,3,)))\n",
        "model.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n",
        "model.add(MaxPool2D(2,2))\n",
        "model.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n",
        "model.add(MaxPool2D(2,2))\n",
        "model.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(20,activation='relu'))\n",
        "model.add(Dense(15,activation='relu'))\n",
        "model.add(Dense(4,activation = 'softmax'))\n",
        "\n",
        "model.compile(\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'],\n",
        "              optimizer='adam'\n",
        "             )"
      ],
      "metadata": {
        "id": "Mw-gYtlGcKzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "K-YPvNcBcL32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = model.fit(x_train,y_train,epochs=10,batch_size=50,validation_data=(x_val,y_val))"
      ],
      "metadata": {
        "id": "Yxq4LGsKcNMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fla4X1c8cOhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ao3MryClcQYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating model on validation data\n",
        "evaluate = model.evaluate(x_val,y_val)\n",
        "print(evaluate)"
      ],
      "metadata": {
        "id": "_yc01-iIcRqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing predictions and the actual label\n",
        "checkImage = test_images[0:1]\n",
        "checklabel = test_labels[0:1]\n",
        "\n",
        "predict = model.predict(np.array(checkImage))\n",
        "\n",
        "output = { 0:'apple',1:'banana',2:'mixed',3:'orange'}\n",
        "\n",
        "print(\"Actual :- \",checklabel)\n",
        "print(\"Predicted :- \",output[np.argmax(predict)])"
      ],
      "metadata": {
        "id": "jTz77l39cSq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWdafRvscTkQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}